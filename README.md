<h1 align="center">
Xmodel_VLM: A Simple Baseline for Multimodal Vision Language Model
</h1>

<h5 align="center">

[![hf_space](https://img.shields.io/badge/ğŸ¤—-MTGV%20HuggingFace-blue.svg)]()
[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)]()
[![github](https://img.shields.io/badge/-Github-black?logo=github)]()[![github](https://img.shields.io/github/)](https://github.com/)  

</h5>





## ğŸ› ï¸ Install

1. Clone this repository and navigate to MobileVLM folder
   ```bash
   git clone https://github.com/
   cd xmodelvlm
   ```

2. Install Package
    ```Shell
    conda create -n xmodelvlm python=3.10 -y
    conda activate xmodelvlm
    pip install --upgrade pip
    pip install -r requirements.txt
    ```

## ğŸ—ï¸ Quick Start

#### Example for Xmodel_VLM model inference
```python


```

## ğŸªœ Step-by-step Tutorial

### Xmodel_VLM

#### 1ï¸âƒ£ Prepare Xmodel_VLM checkpoints

#### 2ï¸âƒ£ Prepare data

#### 3ï¸âƒ£ Run everything with one click!


## ğŸ¤ Acknowledgments


## âœï¸ Reference


